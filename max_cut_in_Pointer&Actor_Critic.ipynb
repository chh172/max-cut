{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "max-cut-in-Pointer&Actor-Critic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOh/NlFxaMQ8xtgwlM1kyb8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chh172/max-cut/blob/main/max_cut_in_Pointer%26Actor_Critic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XViDljAey-BG",
        "outputId": "e6a94061-1453-4281-e1b8-ca9d6a118f65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random \n",
        "import tensorflow as tf\n",
        "from networkx import *\n",
        "n = 6\n",
        "p = 0.5\n",
        "g = erdos_renyi_graph(n, p)\n",
        "print(g. nodes)\n",
        "# [0, 1, 2, 3, 4, 5] \n",
        "print(g. edges)\n",
        "# [(0, 1), (0, 2), (0, 4), (1, 2), (1, 5), (3, 4), (4, 5)]\n",
        "vertices = 5\n",
        "A = adjacency_matrix(erdos_renyi_graph(vertices, 0.5)).todense()\n",
        "A = tf.cast(A,tf.float32)\n",
        "print(A)\n",
        "#B = tf.concat([A,tf.zeros([1,5])],0)\n",
        "#print(B)\n",
        "#C = tf.concat([B,tf.zeros([6,1])],1)\n",
        "#print(C)\n",
        "#D = adjacency_matrix(erdos_renyi_graph(vertices, 0.5)).todense()\n",
        "#D = tf.cast(D,tf.float32)\n",
        "#print(D)\n",
        "#print(A-D)\n",
        "#print(tf.norm(A-D))\n",
        "#print (1<2)\n",
        "print(A[0][4])"
      ],
      "metadata": {
        "id": "9f-O7ecEb4Aj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "781a91a5-b955-45d8-93a9-22ea21561b35"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2, 3, 4, 5]\n",
            "[(0, 2), (0, 3), (0, 4), (0, 5), (1, 2), (1, 3), (1, 5), (2, 3), (3, 4), (4, 5)]\n",
            "tf.Tensor(\n",
            "[[0. 1. 1. 1. 1.]\n",
            " [1. 0. 1. 0. 0.]\n",
            " [1. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 1. 0.]], shape=(5, 5), dtype=float32)\n",
            "tf.Tensor(1.0, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from networkx import *\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "import keras.backend as K\n",
        "# from keras.engine import InputSpec\n",
        "from tensorflow.keras.layers import InputSpec\n",
        "from keras.activations import tanh, softmax\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "\n",
        "# copyright to https://github.com/keon/pointer-networks\n",
        "class Attention(keras.layers.Layer):\n",
        "    \"\"\"\n",
        "        Attention layer\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, hidden_dimensions, name='attention'):\n",
        "        super(Attention, self).__init__(name=name, trainable=True)\n",
        "        self.W1 = keras.layers.Dense(hidden_dimensions, use_bias=False)\n",
        "        self.W2 = keras.layers.Dense(hidden_dimensions, use_bias=False)\n",
        "        self.V = keras.layers.Dense(1, use_bias=False)\n",
        "\n",
        "    def call(self, encoder_outputs, dec_output, mask=None):\n",
        "\n",
        "        w1_e = self.W1(encoder_outputs)\n",
        "        w2_d = self.W2(dec_output)\n",
        "        tanh_output = tanh(w1_e + w2_d)\n",
        "        v_dot_tanh = self.V(tanh_output)\n",
        "        #print(v_dot_tanh.shape)\n",
        "        if mask is not None:\n",
        "            v_dot_tanh += (mask * -1e9)\n",
        "        attention_weights = softmax(v_dot_tanh, axis=1)\n",
        "        att_shape = K.shape(attention_weights)\n",
        "        return K.reshape(attention_weights, (att_shape[0], att_shape[1]))\n",
        "\n",
        "\n",
        "class Decoder(keras.layers.Layer):\n",
        "    \"\"\"\n",
        "        Decoder class for PointerLayer\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, hidden_dimensions):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.lstm = keras.layers.LSTM(\n",
        "            hidden_dimensions, return_sequences=False, return_state=True)\n",
        "\n",
        "    def call(self, x, hidden_states):\n",
        "        dec_output, state_h, state_c = self.lstm(\n",
        "            x, initial_state=hidden_states)\n",
        "        return dec_output, [state_h, state_c]\n",
        "\n",
        "    def get_initial_state(self, inputs):\n",
        "        return self.lstm.get_initial_state(inputs)\n",
        "\n",
        "    def process_inputs(self, x_input, initial_states, constants):\n",
        "        return self.lstm._process_inputs(x_input, initial_states, constants)\n",
        "\n",
        "\n",
        "class PointerLSTM(keras.layers.Layer):\n",
        "    \"\"\"\n",
        "        PointerLSTM\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, hidden_dimensions, name='pointer', **kwargs):\n",
        "        super(PointerLSTM, self).__init__(**kwargs)\n",
        "        self.hidden_dimensions = hidden_dimensions\n",
        "        self.attention = Attention(hidden_dimensions)\n",
        "        self.decoder = Decoder(hidden_dimensions)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        super(PointerLSTM, self).build(input_shape)\n",
        "        self.input_spec = [InputSpec(shape=input_shape)]\n",
        "\n",
        "    def call(self, x, training=None, mask=None, states=None):\n",
        "        \"\"\"\n",
        "        :param Tensor x: Should be the output of the decoder\n",
        "        :param Tensor states: last state of the decoder\n",
        "        :param Tensor mask: The mask to apply\n",
        "        :return: Pointers probabilities\n",
        "        \"\"\"\n",
        "\n",
        "        input_shape = self.input_spec[0].shape\n",
        "        en_seq = x\n",
        "        x_input = x[:, input_shape[1] - 1, :]\n",
        "        x_input = K.repeat(x_input, input_shape[1])\n",
        "        if states:\n",
        "            initial_states = states\n",
        "        else:\n",
        "            initial_states = self.decoder.get_initial_state(x_input)\n",
        "\n",
        "        constants = []\n",
        "        preprocessed_input, _, constants = self.decoder.process_inputs(\n",
        "            x_input, initial_states, constants)\n",
        "        constants.append(en_seq)\n",
        "        last_output, outputs, states = K.rnn(self.step, preprocessed_input,\n",
        "                                             initial_states,\n",
        "                                             go_backwards=self.decoder.lstm.go_backwards,\n",
        "                                             constants=constants,\n",
        "                                             input_length=input_shape[1])\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def step(self, x_input, states):\n",
        "        x_input = K.expand_dims(x_input,1)\n",
        "        input_shape = self.input_spec[0].shape\n",
        "        en_seq = states[-1]\n",
        "        _, [h, c] = self.decoder(x_input, states[:-1])\n",
        "        dec_seq = K.repeat(h, input_shape[1])\n",
        "        probs = self.attention(dec_seq, en_seq)\n",
        "        return probs, [h, c]\n",
        "\n",
        "    def get_output_shape_for(self, input_shape):\n",
        "        # output shape is not affected by the attention component\n",
        "        return (input_shape[0], input_shape[1], input_shape[1])\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], input_shape[1], input_shape[1])"
      ],
      "metadata": {
        "id": "FbGFhCwjtHY9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Description: this function randomly generate a sequence of graphs G(V,E)\n",
        "# where graphs are represented by their adjacency matrix A\n",
        "# and the distribution of V and E are all uniform.\n",
        "\n",
        "import numpy as np\n",
        "from networkx import *\n",
        "import random\n",
        "def graph_batch_generator(batch, vertices):\n",
        "  atlas = []\n",
        "  for i in range(batch):\n",
        "    A = adjacency_matrix(erdos_renyi_graph(vertices, 0.5)).todense()\n",
        "    B = tf.concat([A,tf.zeros([1,vertices])],0)\n",
        "    C = tf.concat([B,tf.zeros([vertices+1,1])],1)\n",
        "    atlas.append(C)\n",
        "  return tf.cast(np.array(atlas),tf.float32)   \n",
        "\n",
        "graphs = graph_batch_generator(2, 5)\n",
        "print(graphs)"
      ],
      "metadata": {
        "id": "HXAwLP_Hh6S3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "980d2be2-c292-47be-b0de-73e726f42a18"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[0. 1. 0. 0. 1. 0.]\n",
            "  [1. 0. 0. 1. 1. 0.]\n",
            "  [0. 0. 0. 1. 0. 0.]\n",
            "  [0. 1. 1. 0. 1. 0.]\n",
            "  [1. 1. 0. 1. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 1. 0. 0. 0. 0.]\n",
            "  [1. 0. 1. 1. 1. 0.]\n",
            "  [0. 1. 0. 1. 0. 0.]\n",
            "  [0. 1. 1. 0. 0. 0.]\n",
            "  [0. 1. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0.]]], shape=(2, 6, 6), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Description: this function randomly generate a random graph G(V,E)\n",
        "# where graph is represented by their adjacency matrix A, plus 'Split'\n",
        "\n",
        "def graph_generator(vertices):\n",
        "  A = adjacency_matrix(erdos_renyi_graph(vertices, 0.5)).todense()\n",
        "  B = tf.concat([A,tf.zeros([1,vertices])],0)\n",
        "  C = tf.concat([B,tf.zeros([vertices+1,1])],1)\n",
        "  return tf.cast(np.array([C]),tf.float32)\n",
        "\n",
        "print(graph_generator(5))"
      ],
      "metadata": {
        "id": "lfxkb4KMs52M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unit testing\n",
        "# atlas = graph_seq_generator(4,1,5)\n",
        "#print(atlas[1])\n",
        "#inp = Input(atlas[1])\n",
        "#print(inp)\n",
        "#for i in range(3):\n",
        "  #print(g[i].nodes)\n",
        "  #\n",
        "  #print(g[i].edges)\n",
        "  #\n",
        "  #print(len(g[i].nodes))\n",
        "#g = random.sample(atlas,2)\n",
        "#print(g[1])\n",
        "#input = input_generator(atlas)\n",
        "#input_2 = tf.cast(np.array([atlas[1]]),tf.float32)\n",
        "#print(input)\n",
        "#print(input_2)\n",
        "#print(input.shape[0])\n",
        "#print(input.shape[1])\n",
        "#print(input.shape[2])\n",
        "#print(input.shape)\n",
        "#print(input.shape)\n",
        "# x = Input(shape=(32,))\n",
        "#x_1 = Input(input)\n",
        "# print(x)\n",
        "# print(graph_generator(5))\n",
        "# print(tf.keras.Input(shape=(10,None,5),tensor=graph_generator(5)))\n",
        "def increment(x):\n",
        "  x = x +1\n",
        "  return\n",
        "x = 1\n",
        "increment(x)\n",
        "print(x)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-bmxoRsJmcc",
        "outputId": "4f53d279-3d5d-4cfe-eb6e-b9b01045047c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.layers import Dense\n",
        "# training/inference main in way 2\n",
        "\n",
        "hidden_size = 128\n",
        "vertices_size = 5\n",
        "batch = 2\n",
        "# input is a [A], where A is the adjacency matrix, which is a square matrix\n",
        "# sequence length shall match the number of rows and feature_dim is number of cols\n",
        "# note the feature for each node is its adjacency relation (row vector in adjacency matrix)\n",
        "seq_len = vertices_size+1\n",
        "feature_dim = vertices_size+1\n",
        "\n",
        "encoder = LSTM(hidden_size,return_sequences = True, name=\"encoder\",return_state=True)\n",
        "actor_decoder = PointerLSTM( hidden_size, name=\"actor_decoder\")\n",
        "critic_decoder = LSTM(hidden_size,name=\"critic_decoder\")\n",
        "value_f = Dense(1)\n",
        "\n",
        "inputs = keras.layers.Input(shape=(seq_len, feature_dim)) \n",
        "encoder_o, state_h, state_c = encoder(inputs)\n",
        "policy = actor_decoder(encoder_o,states=[state_h, state_c])\n",
        "#scores = critic_decoder(encoder_o)\n",
        "decoder_o = critic_decoder(encoder_o)\n",
        "scores = value_f(decoder_o)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=[policy,scores])\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "              loss=tf.keras.losses.Huber(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "graphs = graph_batch_generator(batch,vertices_size)\n",
        "print(graphs)\n",
        "#encoder_outputs, state_h, state_c = encoder(graphs)\n",
        "#print(encoder_outputs)\n",
        "#print(\"hello world\")\n",
        "#policy = actor_decoder(encoder_outputs)\n",
        "#print(policy)\n",
        "#decoder_o = critic_decoder(encoder_outputs)\n",
        "#scores  = value_f(decoder_o)\n",
        "print(\"hello world\")\n",
        "#print(scores)\n",
        "\n",
        "#print(model.predict(graphs)[1][0])"
      ],
      "metadata": {
        "id": "CEWMHPkVeFnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reward(state,action):\n",
        "  return 1.0\n",
        "\n",
        "def value_f_update(critic, delta ,phi, beta):\n",
        "  return phi+ beta*delta*value_grad(critic,phi)\n",
        "\n",
        "def policy_update(actor,alpha,lamb,delta,theta):\n",
        "  return theta + alpha*lamb*delta*policy_grad(actor,theta)\n",
        "  \n",
        "def policy_grad(actor,graphs):\n",
        "  with tf.GradientTape() as tape:\n",
        "    tape.watch(graphs)\n",
        "    y = tf.math.log(actor(graphs))\n",
        "  return tape.gradient(y,actor.trainable_weights) \n",
        "def value_grad(critic,graphs):\n",
        "  with tf.GradientTape() as tape:\n",
        "    tape.watch(graphs)\n",
        "    y = critic(graphs)\n",
        "  return tape.gradient(y, critic.trainable_weights) \n",
        "# MDP construction\n",
        "\n",
        "# 'State space, Action space, and Transition':\n",
        "# In our MDP, a graph as a whole is a state and each graph/non-terminal \n",
        "# state is associated with its characteristic action space A_s\n",
        "# i.e. the whole action action space A = U_s A_s partitioned by each state.\n",
        "# Moreover, we define a uniform terminal state s_t, i.e. p(s,a_s) := s_t for \n",
        "# any state s and its accompanied action a_s, where p is the transition function.\n",
        "\n",
        "# 'Reward':\n",
        "# Reward r of the action a_s from the state/graph s is defined to be \n",
        "# the cut-value produced by the cut of s under action a_s, \n",
        "# i.e. r(s,a_s) := cut_Value(s^{a_s}), \n",
        "# where s^{a_s} is the cut of s under action a_s. \n",
        "\n"
      ],
      "metadata": {
        "id": "UuBJub5Wd6dR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense\n",
        "# training main in way 2\n",
        "\n",
        "# constants, alpha,beta learning rate\n",
        "disc_rate = 0.95\n",
        "alpha = 0.01\n",
        "beta = 0.01\n",
        "\n",
        "# model construction\n",
        "def model_constr(vertices_size, hidden_size):\n",
        "\n",
        "  # input is a [A], where A is the adjacency matrix, which is a square matrix\n",
        "  # sequence length shall match the number of rows and feature_dim is number of cols\n",
        "  # note the feature for each node is its adjacency relation (row vector in adjacency matrix)\n",
        "  seq_len = vertices_size+1\n",
        "  feature_dim = vertices_size+1\n",
        "\n",
        "  encoder = LSTM(hidden_size, trainable=True,return_sequences = True, name=\"encoder\",return_state=True)\n",
        "  actor_decoder = PointerLSTM(hidden_size, trainable=True, name=\"actor_decoder\")\n",
        "  critic_decoder = LSTM(hidden_size, trainable=True,name=\"critic_decoder\")\n",
        "  value_f = Dense(1)\n",
        "\n",
        "  inputs = keras.layers.Input(shape=(seq_len, feature_dim)) \n",
        "  encoder_o, state_h, state_c = encoder(inputs)\n",
        "  policy = actor_decoder(encoder_o,states=[state_h, state_c])\n",
        "  decoder_o = critic_decoder(encoder_o)\n",
        "  scores = value_f(decoder_o)\n",
        "\n",
        "  actor = tf.keras.Model(inputs=inputs, outputs=policy)\n",
        "  critic = tf.keras.Model(inputs=inputs, outputs=scores)\n",
        "  actor.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "                loss=tf.keras.losses.Huber(),\n",
        "                metrics=['accuracy'])\n",
        "  critic.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "                loss=tf.keras.losses.Huber(),\n",
        "                metrics=['accuracy'])\n",
        "  # model = tf.keras.Model(inputs=inputs, outputs=[policy,scores])\n",
        "  # model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "              # loss=tf.keras.losses.Huber(),\n",
        "              # metrics=['accuracy'])\n",
        "\n",
        "\n",
        "  return [actor,critic]\n",
        "\n",
        "# MDP construction\n",
        "\n",
        "# 'State space, Action space, and Transition':\n",
        "# In our MDP, a graph as a whole is a state and each graph/non-terminal \n",
        "# state is associated with its characteristic action space A_s\n",
        "# i.e. the whole action action space A = U_s A_s partitioned by each state.\n",
        "# Moreover, we define a uniform terminal state s_t, i.e. p(s,a_s) := s_t for \n",
        "# any state s and its accompanied action a_s, where p is the transition function.\n",
        "\n",
        "# 'Reward':\n",
        "# Reward r of the action a_s from the state/graph s is defined to be \n",
        "# the cut-value produced by the cut of s under action a_s, \n",
        "# i.e. r(s,a_s) := cut_Value(s^{a_s}), \n",
        "# where s^{a_s} is the cut of s under action a_s. \n",
        "\n",
        "\n",
        "\n",
        "# actor-critic training\n",
        "def training(batch, vertices_size, hidden_size):\n",
        "  graphs = graph_batch_generator(batch,vertices_size)\n",
        "  actor, critic = model_constr(vertices_size, hidden_size)\n",
        "\n",
        "  # randomly init 'phi', 'theta' (already set)\n",
        "\n",
        "  lamb = 1\n",
        "    # do until theta converges (loop for every graph)\n",
        "  converge = False\n",
        "  for i in range(batch):\n",
        "    # randomly init 'phi', 'theta' (already set)\n",
        "    phi = critic.trainable_weights\n",
        "    theta = actor.trainable_weights\n",
        "    # init starting state\n",
        "    s = graphs[i]\n",
        "    # s virtually transitioned to terminal, but in fact stay the same till convergence\n",
        "    while not converge :\n",
        "      # In state 's', select action 'a' given by actor\n",
        "      a = actor.predict(graphs)[i]\n",
        "      # perform 'a' and collect reward r and new state (terminal state)\n",
        "      r = reward(s,a)        \n",
        "      # update delta\n",
        "      # print(critic.predict(graphs)[i].dtype)\n",
        "      delta = r - critic.predict(graphs)[i] \n",
        "      # update value function parameter 'phi'\n",
        "      phi = value_f_update(critic, delta ,phi, beta)\n",
        "      critic.set_weights(phi)\n",
        "      # update policy parameter 'theta'\n",
        "      theta_p = policy_update(actor,alpha,lamb,delta,theta)\n",
        "      # update loop condition\n",
        "      converge = tf.norm(theta - theta_p) < 0.5\n",
        "      theta = theta_p\n",
        "      # update discount\n",
        "      lamb = lamb * disc_rate \n",
        "  return [actor, critic]\n",
        "\n",
        "batch = 2\n",
        "vertices_size = 3\n",
        "hidden_size = 4\n",
        "#graphs = graph_batch_generator(batch,vertices_size)\n",
        "#print(graphs)\n",
        "#actor, critic = model_constr(vertices_size, hidden_size)\n",
        "print(\"hello world\")\n",
        "#print(scores)\n",
        "# print(model.trainable_weights)\n",
        "#print(actor.predict(graphs))\n",
        "#print(critic.predict(graphs))\n",
        "# print(batch)\n",
        "actor, critic = training(batch, vertices_size, hidden_size)"
      ],
      "metadata": {
        "id": "TBYsGYKkscVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = 2\n",
        "vertices_size = 3\n",
        "hidden_size = 4\n",
        "graphs = graph_batch_generator(batch,vertices_size)\n",
        "actor, critic = model_constr(vertices_size, hidden_size)\n",
        "print(actor.predict(graphs))\n",
        "print(critic.predict(graphs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNx61mXqsxni",
        "outputId": "c4217100-98f7-4312-dc04-87f515f3ef09"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0.253188   0.25789192 0.24348596 0.24543417]\n",
            "  [0.25319415 0.25787926 0.24348995 0.24543662]\n",
            "  [0.25319743 0.25787112 0.24349274 0.24543874]\n",
            "  [0.253199   0.25786665 0.24349438 0.24544004]]\n",
            "\n",
            " [[0.25150052 0.25787047 0.24460709 0.24602196]\n",
            "  [0.2515133  0.2578734  0.24459597 0.2460174 ]\n",
            "  [0.25152126 0.25787464 0.24458958 0.24601452]\n",
            "  [0.25152603 0.25787532 0.244586   0.24601269]]]\n",
            "[[-0.05615778]\n",
            " [-0.01478709]]\n"
          ]
        }
      ]
    }
  ]
}